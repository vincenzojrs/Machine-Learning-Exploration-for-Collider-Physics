{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_importing(verbose = True):\n",
    "\n",
    "    # Features list we are interested in\n",
    "    features_list = [12, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 52]\n",
    "\n",
    "    # Get file\n",
    "    f = h5py.File('tutorials/Data/JetDataset/jetImage_7_100p_30000_40000.h5')\n",
    "\n",
    "    # Enclose the file in a numpy array and retrieve information about that\n",
    "    images = np.array(f.get(\"jetImage\"))\n",
    "\n",
    "    if verbose == True:\n",
    "        print('The file contains {} bidimensional item, each having {} rows x {} columns. They resemble an image.\\n'\\\n",
    "                            .format(images.shape[0], images.shape[1], images.shape[2]))\n",
    "\n",
    "    # For each item, extract the X's features\n",
    "    feature_names = (f.get(\"jetFeatureNames\"))[features_list]\n",
    "\n",
    "    # Print the names of the features\n",
    "    if verbose == True:\n",
    "        print('Names of the features:\\n', feature_names)\n",
    "\n",
    "    feature = pd.DataFrame(f.get(\"jets\")[:,features_list], columns = feature_names)\n",
    "    feature.columns = feature.columns.astype(str)\n",
    "\n",
    "    if verbose == True:\n",
    "        print('\\nPrint the dataset: \\n', feature.head(1))\n",
    "\n",
    "    # For each item, extract the y's feature. The y's are one hot encoded, so we're dealing with a multiclass clusterization problem.\n",
    "    target = pd.DataFrame(f.get('jets')[0:,-6:-1])\n",
    "    if verbose == True:\n",
    "        print(\"\\nSample y's row:\\n\", target[0:1])\n",
    "\n",
    "    return images, feature, feature_names, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def replace_numbers_with_letters(dataset, mode = 'letter'):\n",
    "    df = pd.DataFrame(columns=['label'], data=dataset.idxmax(axis=1))\n",
    "    if mode == 'letter':\n",
    "        df = df.applymap(lambda x: 'A' if x == 0 else x)\n",
    "        df = df.applymap(lambda x: 'B' if x == 1 else x)\n",
    "        df = df.applymap(lambda x: 'C' if x == 2 else x)\n",
    "        df = df.applymap(lambda x: 'D' if x == 3 else x)\n",
    "        df = df.applymap(lambda x: 'E' if x == 4 else x)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# 80% of the dataset will be used as train and the remaining part as testing\n",
    "# Using \"stratify\" we make sure the random shuffling will take into account the original distribution of each class\n",
    "\n",
    "# Define train/test dataset splitting, scaling implemented\n",
    "def train_test(dataset, scaling = False):\n",
    "    X = dataset.iloc[:,:dataset.shape[1]-1]\n",
    "    y = dataset.iloc[:,-1]\n",
    "\n",
    "    if scaling == True:\n",
    "        X_columns = X.columns.to_list()\n",
    "        X = pd.DataFrame(normalize(X, axis=0), columns=X_columns)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "        test_size=0.2,\n",
    "        stratify=dataset.iloc[:,-1],\n",
    "        random_state=42)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the classification report. \"macro avg\" for precision, recall and f1 will be used as a benchmark\n",
    "def classification_reporting(tuning, model, y_test, y_pred, X_train):\n",
    "    report = classification_report(y_test, y_pred, output_dict = True)\n",
    "    print('{} {} performance using {} features:\\n'.format(tuning, model, X_train.shape[1]),\n",
    "          report['macro avg'])\n",
    "    print('Accuracy score:', accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}